Aim
To implement a Feedforward Neural Network with ReLU activation in Python, using a basic structure with predefined weights, and calculate the output for given input data.

Algorithm
Define Activation Function:
Use ReLU (Rectified Linear Unit) as the activation function:
ReLU
(ùëõ)=max(0ùëõ)
ReLU(n)=max(0,n)
It outputs the input directly if it is positive; otherwise, it outputs zero.
Neural Network Architecture:
Input Layer: Processes the input data (2 features in each input).
Hidden Layer:
Two nodes (node0 and node1) process the input data using the weights for each node and apply the ReLU function.
Second Hidden Layer:
Two nodes (node2 and node3) take the outputs of node0 and node1, apply weights, and pass through ReLU.
Output Layer:
Combines the outputs of node2 and node3, applies weights, and passes through ReLU to generate the final output.

CODE:
print("feed forward neuralnetwork")
import numpy as np
def relu(n):
    return max(0, n)
def feedforward(input_data, weights):
    node0 = relu(np.dot(input_data, weights[0]))
    node1 = relu(np.dot(input_data, weights[1]))
    node2 = relu(np.dot(np.array([node0, node1]), weights[2]))
    node3 = relu(np.dot(np.array([node0, node1]), weights[3]))
    output = relu(np.dot(np.array([node2, node3]), weights[4]))
    return output
inp = np.array([[-1, 2], [2, 2], [3, 3]])
weights = [np.array([3, 3]), np.array([1, 5]), np.array([3, 3]), np.array([1, 5]), np.array([2, -1])]
for x in inp:
    output = feedforward(x, weights)
    print(f"Input: {x}, Output: {output}")
